# pip install "livekit-agents[silero,turn-detector,deepgram,cartesia,openai]~=1.2"
# pip install "livekit-plugins-noise-cancellation~=0.2"
from livekit import agents, rtc
from livekit.agents import AgentServer, AgentSession, Agent, room_io
from livekit.plugins import noise_cancellation, silero, openai, deepgram, cartesia
from livekit.plugins.turn_detector.multilingual import MultilingualModel


## LiveKit
# LIVEKIT_URL=<your LiveKit server URL>
# LIVEKIT_API_KEY=<your API Key>
# LIVEKIT_API_SECRET=<your API Secret>

## LLM
# OPENAI_BASE_URL= '<URL>'
# OPENAI_API_KEY= '<KEY>'

## TTS
# CARTESIA_API_KEY = '<KEY>'

## STT
# DEEPGRAM_API_KEY = '<KEY>'


class ReadBetweenAssistant(Agent):
    def __init__(self) -> None:
        super().__init__(
            instructions=(
                "You are a voice assistant created by æå“, and your name is æ™“æ™´."
                "Your interface with users will be voice. "
                "You should use short and concise responses, and avoiding usage of unpronouncable punctuation."
                "You need to reply in Chinese."
            ),
        )


server = AgentServer()


@server.rtc_session()
async def readbetween_voice_agent(ctx: agents.JobContext):
    room_name = ctx.room.name
    print(f"ğŸ¯ Agent è¢«åˆ†é…åˆ°æˆ¿é—´: {room_name}")

    # æ·»åŠ è¿æ¥çŠ¶æ€ç›‘æ§
    def on_connection_state_change(state: rtc.ConnectionState):
        print(f"ğŸ”„ è¿æ¥çŠ¶æ€: {state}")
        if state == rtc.ConnectionState.CONN_CONNECTED:
            print("âœ… æˆåŠŸè¿æ¥åˆ° LiveKit æœåŠ¡å™¨")
        elif state == rtc.ConnectionState.CONN_DISCONNECTED:
            print("âŒ ä¸ LiveKit æœåŠ¡å™¨æ–­å¼€è¿æ¥")
        elif state == rtc.ConnectionState.CONN_RECONNECTING:
            print("ğŸ”„ æ­£åœ¨é‡æ–°è¿æ¥åˆ° LiveKit æœåŠ¡å™¨")

    ctx.room.on("connection_state_changed", on_connection_state_change)

    # æ·»åŠ å‚ä¸è€…åŠ å…¥ç›‘æ§
    def on_participant_connected(participant: rtc.RemoteParticipant):
        print(f"ğŸ‘¤ å‚ä¸è€…åŠ å…¥: {participant.identity}")

    ctx.room.on("participant_connected", on_participant_connected)

    session = AgentSession(
        stt=deepgram.STT(model="nova-2", language="zh-CN"),
        llm=openai.LLM(model="COSMO-Mind"),
        tts=cartesia.TTS(model="sonic-3", language="zh", voice="7a5d4663-88ae-47b7-808e-8f9b9ee4127b"),
        vad=silero.VAD.load(),
        turn_detection=MultilingualModel(),
    )

    await session.start(
        room=ctx.room,
        agent=ReadBetweenAssistant(),
        room_options=room_io.RoomOptions(
            audio_input=room_io.AudioInputOptions(
                noise_cancellation=lambda
                    params: noise_cancellation.BVCTelephony() if params.participant.kind == rtc.ParticipantKind.PARTICIPANT_KIND_SIP else noise_cancellation.BVC(),
            ),
        ),
    )

    await session.generate_reply(
        instructions="Greet the user, introduce yourself, and offer assistance."
    )


if __name__ == "__main__":
    import os

    if not os.getenv("LIVEKIT_URL") or "your LiveKit server" in os.getenv("LIVEKIT_URL", ""):
        print("âš ï¸  è¿è¡Œåœ¨æœ¬åœ°æ¨¡æ‹Ÿæ¨¡å¼ - æœªè¿æ¥åˆ°å®é™… LiveKit æœåŠ¡å™¨")
    else:
        print("ğŸ”— è¿æ¥åˆ° LiveKit æœåŠ¡å™¨:", os.getenv("LIVEKIT_URL"))
    agents.cli.run_app(server)
    # python new_voice_agent.py start ## æ­£å¸¸å¯åŠ¨
    # python new_voice_agent.py console ## ç»ˆç«¯äº¤äº’å¯åŠ¨
